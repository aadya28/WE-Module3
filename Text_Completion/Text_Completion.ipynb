{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Generate Function that takes chain length as input."
      ],
      "metadata": {
        "id": "ON7-kfdaARru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def tokenize(corpus: str) -> list:\n",
        "    \"\"\"Tokenize the corpus into words.\"\"\"\n",
        "    return corpus.split()\n",
        "\n",
        "def build_transition_probs(words: list, chain_length: int) -> dict:\n",
        "    \"\"\"Build transition probabilities for chains of words.\"\"\"\n",
        "    transition_probs = {}\n",
        "    for i in range(len(words) - chain_length):\n",
        "        current_words = tuple(words[i:i+chain_length])\n",
        "        next_word = words[i + chain_length]\n",
        "        if current_words in transition_probs:\n",
        "            transition_probs[current_words].append(next_word)\n",
        "        else:\n",
        "            transition_probs[current_words] = [next_word]\n",
        "    return transition_probs\n",
        "\n",
        "def generate_text(transition_probs: dict, start_words: tuple, output_length: int, chain_length: int) -> str:\n",
        "    \"\"\"Generate text using Markov Chain.\"\"\"\n",
        "    generated_text = list(start_words)\n",
        "    for _ in range(output_length - chain_length):\n",
        "        current_words = tuple(generated_text[-chain_length:])\n",
        "        if current_words in transition_probs:\n",
        "            next_word = random.choice(transition_probs[current_words])\n",
        "        else:\n",
        "            # If current words not in dictionary, choose a random word from corpus\n",
        "            next_word = random.choice(start_words)\n",
        "        generated_text.append(next_word)\n",
        "    return ' '.join(generated_text)\n",
        "\n",
        "def generate(corpus: str, start_words: list[str], chain_length: int, output_length: int) -> str:\n",
        "    \"\"\"Generate text using Markov Chain.\"\"\"\n",
        "    # Tokenize the corpus\n",
        "    words = tokenize(corpus)\n",
        "\n",
        "    # Build transition probabilities\n",
        "    transition_probs = build_transition_probs(words, chain_length)\n",
        "\n",
        "    # Generate text\n",
        "    return generate_text(transition_probs, tuple(start_words), output_length, chain_length)\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOsOO3s06gby",
        "outputId": "f35f66e2-8dca-466a-9461-6342e2bf643b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lazy cat lazy lazy The cat The cat lazy The cat cat The cat The cat The The The The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_generate():\n",
        "    # Test Case 1: Test with short corpus and chain length 1\n",
        "    corpus = \"The quick brown fox jumps over the lazy dog.\"\n",
        "    generated_text = generate(corpus, [\"The\"], 1, 10)\n",
        "    assert len(generated_text.split()) == 10, \"Test Case 1 Failed\"\n",
        "\n",
        "    # Test Case 2: Test with longer corpus and chain length 2\n",
        "    corpus = \"The quick brown fox jumps over the lazy dog. The lazy dog barks at the moon.\"\n",
        "    generated_text = generate(corpus, [\"The\", \"quick\"], 2, 20)\n",
        "    assert len(generated_text.split()) == 20, \"Test Case 2 Failed\"\n",
        "\n",
        "    # Test Case 3: Test with start words not present in corpus\n",
        "    corpus = \"The quick brown fox jumps over the lazy dog. The lazy dog barks at the moon.\"\n",
        "    generated_text = generate(corpus, [\"A\", \"bird\"], 2, 20)\n",
        "    assert len(generated_text.split()) == 20, \"Test Case 3 Failed\"\n",
        "\n",
        "    # Test Case 4: Test with chain length = corpus length - 2\n",
        "    corpus = \"The quick brown fox jumps over the lazy dog.\"\n",
        "    generated_text = generate(corpus, [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\"], 8, 20)\n",
        "    assert len(generated_text.split()) == 20, \"Test Case 4 Failed\"\n",
        "\n",
        "    print(\"All test cases passed successfully!\")\n",
        "\n",
        "# Run test cases\n",
        "test_generate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGK9ml6w_vMH",
        "outputId": "80049f1c-0a8b-4c29-b082-10d24f5c3cb6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All test cases passed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Function that only considers the previous word i.e. chain length is 1."
      ],
      "metadata": {
        "id": "xM1Fw90fAvc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate(corpus: str, start_word: str, output_length: int) -> str:\n",
        "    # Tokenize the corpus into words\n",
        "    words = corpus.split()\n",
        "\n",
        "    # Build a dictionary to store transition probabilities\n",
        "    transition_probs = {}\n",
        "    for i in range(len(words) - 1):\n",
        "        current_word = words[i]\n",
        "        next_word = words[i + 1]\n",
        "        if current_word in transition_probs:\n",
        "            transition_probs[current_word].append(next_word)\n",
        "        else:\n",
        "            transition_probs[current_word] = [next_word]\n",
        "\n",
        "    # Generate text using Markov Chain\n",
        "    current_word = start_word\n",
        "    generated_text = [current_word]\n",
        "    for _ in range(output_length - 1):\n",
        "        if current_word in transition_probs:\n",
        "            next_word = random.choice(transition_probs[current_word])\n",
        "        else:\n",
        "            # If current word not in dictionary, choose a random word from corpus\n",
        "            next_word = random.choice(words)\n",
        "        generated_text.append(next_word)\n",
        "        current_word = next_word\n",
        "\n",
        "    return ' '.join(generated_text)\n",
        "\n",
        "# Example usage:\n",
        "corpus = \"The quick brown fox jumps over the lazy dog. The lazy dog barks at the moon. Moonlight shines through the window. The window is open. Open the door slowly.\"\n",
        "generated_text = generate(corpus, \"The\", 50)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDBH_jZ3zpD2",
        "outputId": "daab898d-a851-4ebf-bbc5-f19ddf445f26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The window is open. Open the lazy dog barks at the window. The quick brown fox jumps over the moon. Moonlight shines through the window. The lazy dog barks at the door slowly. window. The quick brown fox jumps over the lazy dog. The window is open. Open the door\n"
          ]
        }
      ]
    }
  ]
}